from typing import List, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from sqlalchemy import func

from app.api.deps import get_db, verify_admin_master_key, verify_master_key
from app.models.domain import Client, Agent, Asset, ScanJob, Finding, Partner, PartnerAPIKey, PartnerEarnings, ScanResult
from app.schemas.contracts import ClientRead, ScanJobResponse, PartnerCreate, PartnerRead, PartnerCreateResponse, PartnerAPIKeyCreate, PartnerAPIKeyRead, PartnerUpdateMode
from app.services.cache import cache_service
from app.services.siem import siem_service
import secrets

router = APIRouter(
    dependencies=[Depends(verify_admin_master_key)]
)

@router.get("/overview")
@cache_service.cache(expire=60) # Cache for 1 minute
def get_admin_overview(db: Session = Depends(get_db)):
    """
    Devuelve un resumen global del sistema.
    """
    total_clients = db.query(Client).count()
    total_agents = db.query(Agent).count()
    total_assets = db.query(Asset).count()
    total_findings = db.query(Finding).count()
    total_jobs = db.query(ScanJob).count()
    total_partners = db.query(Partner).count()
    
    # Findings by severity
    findings_by_severity = {
        "critical": db.query(Finding).filter(func.lower(Finding.severity) == "critical").count(),
        "high": db.query(Finding).filter(func.lower(Finding.severity) == "high").count(),
        "medium": db.query(Finding).filter(func.lower(Finding.severity) == "medium").count(),
        "low": db.query(Finding).filter(func.lower(Finding.severity) == "low").count(),
    }
    
    active_agents = db.query(Agent).filter(Agent.status == "online").count()
    suspended_clients = db.query(Client).filter(Client.status == "suspended").count()
    
    # Last 10 findings
    last_findings = db.query(Finding).order_by(Finding.detected_at.desc()).limit(10).all()
    
    # Format last findings for UI
    formatted_findings = []
    for f in last_findings:
        formatted_findings.append({
            "id": f.id,
            "title": f.title,
            "severity": f.severity,
            "client_name": f.asset.client.name if f.asset and f.asset.client else "Unknown",
            "asset_ip": f.asset.ip if f.asset else "Unknown",
            "detected_at": f.detected_at
        })

    return {
        "total_clients": total_clients,
        "total_agents": total_agents,
        "total_assets": total_assets,
        "total_findings": total_findings,
        "total_jobs": total_jobs,
        "total_partners": total_partners,
        "findings_by_severity": findings_by_severity,
        "active_agents": active_agents,
        "suspended_clients": suspended_clients,
        "last_findings": formatted_findings
    }

@router.get("/clients")
@cache_service.cache(expire=60) # Cache for 1 minute
def list_all_clients(db: Session = Depends(get_db)):
    clients = db.query(Client).order_by(Client.created_at.desc()).all()
    # Enrich with counts
    result = []
    for c in clients:
        result.append({
            "id": c.id,
            "name": c.name,
            "contact_email": c.contact_email,
            "status": c.status,
            "created_at": c.created_at,
            "agents_count": len(c.agents),
            "assets_count": len(c.assets),
            "jobs_count": len(c.scan_jobs)
        })
    return result

@router.get("/agents")
@cache_service.cache(expire=60) # Cache for 1 minute
def list_all_agents(db: Session = Depends(get_db)):
    agents = db.query(Agent).order_by(Agent.last_seen_at.desc()).all()
    result = []
    for a in agents:
        result.append({
            "id": a.id,
            "hostname": a.hostname,
            "status": a.status,
            "last_seen_at": a.last_seen_at,
            "client_name": a.client.name if a.client else "Unknown",
            "version": "1.0.0" # Placeholder
        })
    return result


@router.get("/agents/{agent_id}/debug")
def debug_agent(
    agent_id: str,
    db: Session = Depends(get_db),
):
    """
    Devuelve una foto r√°pida del estado del agente y su √∫ltimo job.
    √ötil para soporte/diagn√≥stico remoto.
    """
    agent = db.query(Agent).filter(Agent.id == agent_id).first()
    if not agent:
        raise HTTPException(status_code=404, detail="Agente no encontrado")

    last_job = (
        db.query(ScanJob)
        .filter(ScanJob.agent_id == agent.id)
        .order_by(ScanJob.created_at.desc())
        .first()
    )
    pending_job = (
        db.query(ScanJob)
        .filter(
            ScanJob.client_id == agent.client_id,
            ScanJob.status.in_(["pending", "running"]),
            ((ScanJob.agent_id == None) | (ScanJob.agent_id == agent.id)),  # noqa
        )
        .order_by(ScanJob.created_at.desc())
        .first()
    )

    return {
        "agent": {
            "id": agent.id,
            "hostname": agent.hostname,
            "status": agent.status,
            "last_seen_at": agent.last_seen_at,
            "client_id": agent.client_id,
        },
        "last_job": {
            "id": last_job.id if last_job else None,
            "type": last_job.type if last_job else None,
            "status": last_job.status if last_job else None,
            "target": last_job.target if last_job else None,
            "updated_at": last_job.finished_at or last_job.started_at if last_job else None,
        } if last_job else None,
        "next_pending_job": {
            "id": pending_job.id if pending_job else None,
            "type": pending_job.type if pending_job else None,
            "status": pending_job.status if pending_job else None,
            "target": pending_job.target if pending_job else None,
            "assigned_agent": pending_job.agent_id if pending_job else None,
        } if pending_job else None,
    }

@router.get("/jobs")
@cache_service.cache(expire=60) # Cache for 1 minute
def list_all_jobs(db: Session = Depends(get_db)):
    jobs = db.query(ScanJob).order_by(ScanJob.created_at.desc()).limit(50).all()
    result = []
    for j in jobs:
        result.append({
            "id": j.id,
            "type": j.type,
            "target": j.target,
            "status": j.status,
            "created_at": j.created_at,
            "client_name": j.client.name if j.client else "Unknown"
        })
    return result

@router.delete("/jobs/{job_id}")
def delete_job_admin(
    job_id: str,
    db: Session = Depends(get_db),
    _ = Depends(verify_admin_master_key)
):
    """
    Elimina un Job por ID (Admin).
    """
    job = db.query(ScanJob).filter(ScanJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job no encontrado")

    # Opcional: Limpiar resultados asociados si se desea
    # db.query(ScanResult).filter(ScanResult.scan_job_id == job.id).delete()

    db.delete(job)
    db.commit()
    return {"status": "deleted", "id": job_id}

@router.get("/findings")
@cache_service.cache(expire=60) # Cache for 1 minute
def list_all_findings(db: Session = Depends(get_db)):
    findings = db.query(Finding).order_by(Finding.detected_at.desc()).limit(50).all()
    result = []
    for f in findings:
        result.append({
            "id": f.id,
            "title": f.title,
            "severity": f.severity,
            "client_name": f.asset.client.name if f.asset and f.asset.client else "Unknown",
            "asset_ip": f.asset.ip if f.asset else "Unknown",
            "detected_at": f.detected_at
        })
    return result

@router.delete("/clients/{client_id}")
def delete_client_admin(
    client_id: str,
    db: Session = Depends(get_db),
    _ = Depends(verify_admin_master_key)
):
    client = db.query(Client).filter(Client.id == client_id).first()
    if not client:
        raise HTTPException(status_code=404, detail="Cliente no encontrado")

    # Manual Cascade Delete
    try:
        # 1. Partner Earnings (linked to client)
        db.query(PartnerEarnings).filter(PartnerEarnings.client_id == client.id).delete(synchronize_session=False)

        # 2. Scan Results (linked to jobs)
        jobs = db.query(ScanJob).filter(ScanJob.client_id == client.id).all()
        job_ids = [j.id for j in jobs]
        if job_ids:
            db.query(ScanResult).filter(ScanResult.scan_job_id.in_(job_ids)).delete(synchronize_session=False)

        # 3. Scan Jobs
        db.query(ScanJob).filter(ScanJob.client_id == client.id).delete(synchronize_session=False)
        
        # 4. Findings (via Assets or direct client_id if applicable)
        db.query(Finding).filter(Finding.client_id == client.id).delete(synchronize_session=False)
        
        # 5. Assets
        db.query(Asset).filter(Asset.client_id == client.id).delete(synchronize_session=False)
        
        # 6. Agents
        db.query(Agent).filter(Agent.client_id == client.id).delete(synchronize_session=False)
        
        # 7. Subscription
        if client.subscription:
            db.delete(client.subscription)

        # 8. Client
        db.delete(client)
        db.commit()
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Error al eliminar cliente: {str(e)}")
    
    return {"status": "deleted", "id": client_id}



@router.delete("/agents/{agent_id}")
def delete_agent_admin(
    agent_id: str,
    db: Session = Depends(get_db),
    _ = Depends(verify_admin_master_key)
):
    """
    Elimina un agente globalmente.
    """
    agent = db.query(Agent).filter(Agent.id == agent_id).first()
    if not agent:
        raise HTTPException(status_code=404, detail="Agente no encontrado")

    try:
        # Desvincular jobs que estuvieran asignados a este agente
        # Opcional: ponerlos en pending de nuevo o borrarlos. 
        # Si el job estaba running, mejor lo fallamos o lo re-encolamos.
        # Aqu√≠ simplemente los desvinculamos (agent_id=None) y status=pending
        running_jobs = db.query(ScanJob).filter(ScanJob.agent_id == agent.id, ScanJob.status == "running").all()
        for job in running_jobs:
            job.agent_id = None
            job.status = "pending"
        
        # Desvincular assets descubiertos por este agente
        # NOTA: Asset.agent_id est√° comentado en el modelo, as√≠ que omitimos este paso por ahora.
        # assets = db.query(Asset).filter(Asset.agent_id == agent.id).all()
        # for asset in assets:
        #     asset.agent_id = None
        
        db.delete(agent)
        db.commit()
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Error al eliminar agente: {str(e)}")

    return {"status": "deleted", "id": agent_id}


@router.delete("/partners/{partner_id}")
def delete_partner(
    partner_id: str,
    db: Session = Depends(get_db),
    _ = Depends(verify_master_key)
):
    partner = db.query(Partner).filter(Partner.id == partner_id).first()
    if not partner:
        raise HTTPException(status_code=404, detail="Partner not found")
    
    # Check for active clients (Disabled as Client.partner_id is currently commented out)
    # active_clients = db.query(Client).filter(Client.partner_id == partner.id).count()
    # if active_clients > 0:
    #     raise HTTPException(
    #         status_code=400, 
    #         detail=f"No se puede eliminar el partner. Tiene {active_clients} clientes asociados. Elim√≠nelos o reas√≠gnelos primero."
    #     )

    try:
        # Delete API Keys
        db.query(PartnerAPIKey).filter(PartnerAPIKey.partner_id == partner.id).delete(synchronize_session=False)
        
        # Delete Earnings records
        db.query(PartnerEarnings).filter(PartnerEarnings.partner_id == partner.id).delete(synchronize_session=False)

        db.delete(partner)
        db.commit()
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Error al eliminar partner: {str(e)}")

    return {"status": "success", "message": "Partner deleted"}


@router.get("/system/health")
def system_health(db: Session = Depends(get_db), _ = Depends(verify_admin_master_key)):
    # Check DB
    db_status = "error"
    try:
        db.execute(func.text("SELECT 1"))
        db_status = "ok"
    except Exception as e:
        print(f"DB Health Error: {e}")
        pass
        
    # Check Redis
    redis_status = "error"
    try:
        if cache_service.redis_client.ping():
            redis_status = "ok"
    except Exception as e:
        print(f"Redis Health Error: {e}")
        pass

    return {
        "orchestrator": "ok",
        "database": db_status,
        "redis": redis_status,
        "environment": "Production",
        "version": "3.0.0"
    }

# ============================
# PARTNER MANAGEMENT
# ============================

@router.post("/partners", response_model=PartnerCreateResponse)
def create_partner(payload: PartnerCreate, db: Session = Depends(get_db)):
    # Check email
    existing = db.query(Partner).filter(Partner.email == payload.email).first()
    if existing:
        raise HTTPException(status_code=400, detail="Email ya registrado")

    # Determinar modo (demo/full)
    mode = (payload.account_mode or (payload.type.lower() if payload.type else None) or "demo").lower()

    # Handle Password
    raw_password = payload.password
    if not raw_password:
        raw_password = secrets.token_urlsafe(12)
    
    # Determine Limits based on Type
    p_type = payload.type or mode.upper()
    client_limit = 1 if mode == "demo" else 20
    agent_limit = 1 if mode == "demo" else 20
    demo_expires = None
    
    if mode == "demo":
        from datetime import datetime, timedelta, timezone
        demo_expires = datetime.now(timezone.utc) + timedelta(days=30)
    
    partner = Partner(
        name=payload.name,
        email=payload.email,
        hashed_password=raw_password, # In prod: hash it!
        status="active",
        type=p_type,
        account_mode=mode,
        client_limit=client_limit,
        agent_limit=agent_limit,
        demo_expires_at=demo_expires
    )
    db.add(partner)
    db.commit()
    db.refresh(partner)

    # Auto-generate initial API Key
    new_key = secrets.token_hex(32)
    api_key_record = PartnerAPIKey(
        partner_id=partner.id,
        name="Default Key",
        api_key=new_key,
        active=True
    )
    db.add(api_key_record)
    db.commit()

    # Prepare response with generated password
    response = PartnerCreateResponse.model_validate(partner)
    response.generated_password = raw_password
    response.api_key = new_key
    return response

@router.get("/partners", response_model=List[PartnerRead])
@cache_service.cache(expire=60) # Cache for 1 minute
def list_partners(db: Session = Depends(get_db)):
    return db.query(Partner).order_by(Partner.created_at.desc()).all()

@router.get("/risk-radar")
@cache_service.cache(expire=300) # Cache for 5 minutes
def get_risk_radar(
    db: Session = Depends(get_db),
    _ = Depends(verify_master_key)
):
    """
    Calcula las m√©tricas para el gr√°fico de radar de riesgo.
    """
    # 1. Vulnerabilidades (0-100)
    # Ratio de findings criticos/altos vs total activos
    total_assets = db.query(Asset).count() or 1
    critical_findings = db.query(Finding).filter(Finding.severity.in_(["critical", "high"])).count()
    vuln_score = min(100, (critical_findings / total_assets) * 20) if total_assets > 0 else 0

    # 2. Exposici√≥n (0-100)
    # Basado en puertos abiertos (simulado con findings de tipo 'port')
    # Por ahora usaremos un proxy: % de activos con findings
    assets_with_findings = db.query(Asset.id).join(Finding).distinct().count()
    exposure_score = (assets_with_findings / total_assets) * 100 if total_assets > 0 else 0

    # 3. Anomal√≠as (0-100)
    # Usar√≠amos el AI Engine aqu√≠. Por ahora, mock basado en findings recientes
    anomaly_score = min(100, critical_findings * 5)

    # 4. Configuraci√≥n (0-100)
    # Mock: Asumimos que el 80% est√° bien configurado
    config_score = 20 # 20% de riesgo de configuraci√≥n (bajo es bueno en radar? o alto es riesgo?)
    # Asumimos que el radar muestra RIESGO, as√≠ que alto es malo.
    
    # 5. Cobertura (0-100)
    # Riesgo por falta de cobertura. 
    # Si tenemos 10 clientes y 5 agentes, cobertura 50%, riesgo 50%.
    total_clients = db.query(Client).count() or 1
    total_agents = db.query(Agent).count()
    coverage_ratio = min(1, total_agents / total_clients) # Simplificaci√≥n
    coverage_risk = (1 - coverage_ratio) * 100

    return [
        {"subject": "Vulnerabilidades", "A": int(vuln_score), "fullMark": 100},
        {"subject": "Exposici√≥n", "A": int(exposure_score), "fullMark": 100},
        {"subject": "Mala Configuraci√≥n", "A": int(config_score), "fullMark": 100},
        {"subject": "Anomal√≠as IA", "A": int(anomaly_score), "fullMark": 100},
        {"subject": "Falta de Cobertura", "A": int(coverage_risk), "fullMark": 100},
    ]

@router.get("/network-topology")
@cache_service.cache(expire=300) # Cache for 5 minutes
def get_network_topology(
    db: Session = Depends(get_db),
    _ = Depends(verify_master_key)
):
    """
    Devuelve nodos y aristas para React Flow.
    """
    nodes = []
    edges = []
    
    # 1. Clientes como Grupos/Nodos Centrales
    clients = db.query(Client).all()
    y_offset = 0
    
    for client in clients:
        client_node_id = f"client-{client.id}"
        nodes.append({
            "id": client_node_id,
            "type": "input", # Input node for the cluster
            "data": {"label": f"üè¢ {client.name}"},
            "position": {"x": 250, "y": y_offset},
            "style": {"background": "#6366f1", "color": "white", "width": 200}
        })
        
        # 2. Activos del Cliente
        assets = db.query(Asset).filter(Asset.client_id == client.id).all()
        x_offset = 0
        for i, asset in enumerate(assets):
            asset_node_id = f"asset-{asset.id}"
            nodes.append({
                "id": asset_node_id,
                "data": {"label": f"üñ•Ô∏è {asset.ip}\n{asset.hostname or ''}"},
                "position": {"x": x_offset, "y": y_offset + 150},
            })
            
            # Conexi√≥n Cliente -> Activo
            edges.append({
                "id": f"e-{client_node_id}-{asset_node_id}",
                "source": client_node_id,
                "target": asset_node_id,
                "animated": True
            })
            x_offset += 200
            
        y_offset += 300

    return {"nodes": nodes, "edges": edges}

@router.patch("/partners/{partner_id}/reset-password", response_model=Dict[str, str])
def reset_partner_password(partner_id: str, db: Session = Depends(get_db)):
    partner = db.query(Partner).filter(Partner.id == partner_id).first()
    if not partner:
        raise HTTPException(status_code=404, detail="Partner no encontrado")
    
    new_password = secrets.token_urlsafe(12)
    partner.hashed_password = new_password # In prod: hash it!
    db.commit()
    
    return {"password": new_password}

@router.get("/global-stats", response_model=Dict[str, Any])
@cache_service.cache(expire=60)
def get_global_stats(db: Session = Depends(get_db)):
    """
    Devuelve estad√≠sticas globales de amenazas desde Redis.
    """
    try:
        r = cache_service.redis_client
        total_threats = int(r.get("global:threats:total") or 0)
        
        # Mock top threats for now if not in redis
        top_threats = [] 
        
        severity_dist = {
            "critical": int(r.get("global:threats:severity:critical") or 0),
            "high": int(r.get("global:threats:severity:high") or 0),
            "medium": int(r.get("global:threats:severity:medium") or 0),
            "low": int(r.get("global:threats:severity:low") or 0),
        }
        
        return {
            "total_threats_processed": total_threats,
            "top_threats": top_threats,
            "severity_distribution": severity_dist
        }
    except Exception as e:
        print(f"Error fetching global stats: {e}")
        return {
            "total_threats_processed": 0,
            "top_threats": [],
            "severity_distribution": {"critical": 0, "high": 0, "medium": 0, "low": 0}
        }

@router.get("/partners/{partner_id}")
def get_partner_details(partner_id: str, db: Session = Depends(get_db)):
    partner = db.query(Partner).filter(Partner.id == partner_id).first()
    if not partner:
        raise HTTPException(status_code=404, detail="Partner no encontrado")
    
    # Enrich with clients and api keys
    clients = db.query(Client).filter(Client.partner_id == partner.id).all()
    api_keys = db.query(PartnerAPIKey).filter(PartnerAPIKey.partner_id == partner.id).all()
    
    return {
        "partner": partner,
        "clients": clients,
        "api_keys": api_keys
    }

from app.schemas.contracts import PartnerAPIKeyCreate, PartnerAPIKeyRead
import secrets
from app.models.domain import PartnerAPIKey

@router.post("/partners/{partner_id}/api-keys", response_model=PartnerAPIKeyRead)
def create_partner_api_key_admin(
    partner_id: str,
    payload: PartnerAPIKeyCreate,
    db: Session = Depends(get_db)
):
    partner = db.query(Partner).filter(Partner.id == partner_id).first()
    if not partner:
        raise HTTPException(status_code=404, detail="Partner no encontrado")
        
    new_key = secrets.token_hex(32)
    api_key_record = PartnerAPIKey(
        partner_id=partner.id,
        name=payload.name,
        api_key=new_key,
        active=True
    )
    db.add(api_key_record)
    db.commit()
    db.refresh(api_key_record)
    return api_key_record


@router.patch("/partners/{partner_id}/commission", response_model=PartnerRead)
def update_partner_commission(
    partner_id: str,
    db: Session = Depends(get_db)
):
    # Comisiones deshabilitadas; mantenemos endpoint para compatibilidad
    raise HTTPException(status_code=410, detail="Comisiones deshabilitadas para partners")

@router.patch("/partners/{partner_id}/mode", response_model=PartnerRead)
def update_partner_mode(
    partner_id: str,
    payload: PartnerUpdateMode,
    db: Session = Depends(get_db),
    _ = Depends(verify_admin_master_key)
):
    partner = db.query(Partner).filter(Partner.id == partner_id).first()
    if not partner:
        raise HTTPException(status_code=404, detail="Partner no encontrado")
        
    new_mode = payload.account_mode.lower()
    if new_mode not in ["demo", "full"]:
        raise HTTPException(status_code=400, detail="Modo inv√°lido. Use 'demo' o 'full'.")
        
    partner.account_mode = new_mode
    partner.type = new_mode.upper() # Keep legacy field in sync
    
    # Update limits based on mode
    if new_mode == "demo":
        partner.client_limit = 1
        partner.agent_limit = 1
        # Set expiration if not set? Or reset it? Let's leave it as is or set 30 days from now if null
        if not partner.demo_expires_at:
            from datetime import datetime, timedelta, timezone
            partner.demo_expires_at = datetime.now(timezone.utc) + timedelta(days=30)
    else:
        # Full mode defaults
        partner.client_limit = 20 + (partner.client_packages * 10)
        partner.agent_limit = 20 + (partner.agent_packages * 10)
        partner.demo_expires_at = None
        
    db.commit()
    db.refresh(partner)
    return partner
